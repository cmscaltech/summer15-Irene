{
 "metadata": {
  "name": "",
  "signature": "sha256:feab09318ec5af7e92f4e6d50866a2656a67b40c920eaa801e5d846567c289ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "import pickle\n",
      "import random as r\n",
      "from oNADE import nade\n",
      "import oNADE\n",
      "import NADE\n",
      "import Data,Data.utils\n",
      "import Instrumentation\n",
      "import Optimization\n",
      "import h5py\n",
      "from scipy.stats import chisquare\n",
      "import time\n",
      "from matplotlib.colors import LogNorm\n",
      "from sklearn import preprocessing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Couldn't import dot_parser, loading of dot files will not be possible.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A method that deletes certain cols from data and feature list, useful for removing muons\n",
      "def remove_cols(data, indices, features):\n",
      "    features = np.delete(features, indices)\n",
      "    n_features = len(features)\n",
      "    data = np.delete(data, indices, 1) \n",
      "    return data, features \n",
      "\n",
      "# A method that replaces all the zeros and put them at an unrealistic value\n",
      "def replace_zeros(dataset, mus = None, sigmas = None): \n",
      "    samples = dataset.shape[0] \n",
      "    features = dataset.shape[1] \n",
      "    maxs = dataset.max(axis = 0)\n",
      "    mmax = maxs.max()\n",
      "    copy = np.copy(dataset)\n",
      "    copy[copy == 0] = mmax + 100\n",
      "    mins = copy.min(axis = 0) \n",
      "    if mus!= None and sigmas!= None:\n",
      "        means = mus\n",
      "        stds = sigmas\n",
      "    else:\n",
      "        stds = (maxs - mins)/5\n",
      "        means = 2 * mins - maxs\n",
      "    \n",
      "    print stds\n",
      "\n",
      "    for i in range(features): \n",
      "        for j in range(samples):\n",
      "            if copy[j, i] == mmax + 100:\n",
      "                copy[j, i] = np.random.normal(means[i], stds[i])\n",
      "    return (mins, means, stds, copy)\n",
      "\n",
      "# A method that splits the data into training and testing, and save the arrays to files \n",
      "def split(data, label, ratio = 0.5, io = True, show = False): \n",
      "    \n",
      "    # split into right ratios \n",
      "    np.random.shuffle(data)\n",
      "    dim = len(data)\n",
      "    trndata = data[0:ratio * dim, :] \n",
      "    cvdata, tstdata = np.array_split(data[ratio * dim: dim-1, :], 2, axis = 0)\n",
      "    \n",
      "    # Replace the zeros \n",
      "    mins, mus, sigmas, trndata = replace_zeros(trndata)\n",
      "    a, b, c, tstdata = replace_zeros(tstdata, mus, sigmas)\n",
      "    a, b, c, cvdata = replace_zeros(cvdata, mus, sigmas)\n",
      "    \n",
      "    io_training = None \n",
      "    # Dump into hdf5 files\n",
      "    if io:\n",
      "        print label\n",
      "        io_training = '../Data/%s_nm.hdf5'%label \n",
      "        print io_training\n",
      "        f = h5py.File(io_training, 'a')\n",
      "        print f.keys()\n",
      "        if \"train\" in f.keys():\n",
      "            print 'train exists'\n",
      "            grp = f['train']\n",
      "            del grp['data']\n",
      "            dset = grp.create_dataset('data', data= trndata)\n",
      "            grp.attrs['mus'] = mus\n",
      "            grp.attrs['mins'] = mins\n",
      "            grp.attrs['sigmas'] = sigmas \n",
      "            del f['test']['data']\n",
      "            del f['validation']['data']\n",
      "            f.create_dataset('test/data', data = tstdata)\n",
      "            f.create_dataset('validation/data', data = cvdata)\n",
      "        else:\n",
      "            print 'creating train'\n",
      "            grp = f.create_group('train')\n",
      "            grp.create_dataset('data', data = trndata)\n",
      "            grp.attrs[\"mus\"] = mus\n",
      "            grp.attrs[\"mins\"] = mins\n",
      "            grp.attrs[\"sigmas\"] = sigmas \n",
      "            f.create_group('validation').create_dataset('data', data = cvdata)\n",
      "            f.create_group('test').create_dataset('data', data = tstdata) # don't waste too much data on testing \n",
      "        print f['train']['data'].shape\n",
      "        f.close() \n",
      "    \n",
      "    # Check if everything makes sense \n",
      "    if show: \n",
      "        for i in range(data.shape[-1]):\n",
      "            plt.hist(trndata[:, i], bins = 30, alpha = 0.4, normed = True)\n",
      "            plt.hist(tstdata[:, i], bins = 30, alpha = 0.4, normed = True)\n",
      "            plt.hist(cvdata[:, i], bins = 30, alpha = 0.4, normed = True)\n",
      "            plt.show() \n",
      "    \n",
      "    return trndata, tstdata, io_training\n",
      "\n",
      "# A method that randomly takes a fracture of the data\n",
      "def take(data, ratio): \n",
      "    np.random.shuffle(data)\n",
      "    dim = len(data)\n",
      "    data = data[0:ratio * dim, :] \n",
      "    return data "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datapath = '../../../afs/cern.ch/work/y/yuting/public/razor/'\n",
      "feature_list = ['jetPt:0', 'jetPt:1', 'jetPt:2', 'jetEta:0', 'jetEta:1',\n",
      "                  'jetEta:2', 'jetMass:0', 'jetMass:1', 'jetMass:2', 'muonPt:0', 'muonPt:1',\n",
      "                'elePt:0', 'elePt:1', 'metPt', 'sumMET' ]\n",
      "\n",
      "files = ['QCD_Pt_170to300_TuneCUETP8M1_13TeV_pythia8.hdf5', \n",
      "               'TTJets_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.hdf5',\n",
      "                'WJetsToLNu_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.hdf5']\n",
      "\n",
      "labels = map(lambda pkn: pkn.split('_')[0], files)\n",
      "\n",
      "n_types = len(files)\n",
      "n_features = len(feature_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samples = np.zeros(n_types)\n",
      "datasets = {} \n",
      "n = 200000 # train on this many data \n",
      "io_training = {} \n",
      "# trndata = {} \n",
      "muon_indices = [9, 10]\n",
      "\n",
      "for (i, filename) in enumerate(files):\n",
      "    print filename\n",
      "    f = h5py.File(datapath + filename, 'r')\n",
      "    datasets[i], newlist = remove_cols(f['data'][0:n], muon_indices, feature_list)\n",
      "    print datasets[i].shape\n",
      "    f.close() \n",
      "    trndata, tstdata, io_training[i] = split(datasets[i], labels[i], ratio = 0.2, io = True, show = False)\n",
      "\n",
      "feature_list = newlist\n",
      "print feature_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "QCD_Pt_170to300_TuneCUETP8M1_13TeV_pythia8.hdf5\n",
        "(200000, 13)\n",
        "[  5.41757629e+02   3.84866302e+02   2.67768524e+02   2.39971805e+00\n",
        "   2.39980102e+00   2.39996624e+00   8.83775711e+01   7.26230774e+01\n",
        "   5.03511887e+01   3.80811249e+02   1.91073181e+02   3.74131299e+03\n",
        "   2.27039383e+02]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.47527275e+01   4.00205994e+01   4.00007782e+01  -2.39907694e+00\n",
        "  -2.39998817e+00  -2.39997911e+00  -1.52587891e-05   2.66671133e+00\n",
        "   2.44881010e+00   2.00099545e+01   2.00019989e+01   4.76716705e+02\n",
        "   6.96066543e-02]\n",
        "[  99.40098038   68.96914062   45.55354919    0.959759      0.95995784\n",
        "    0.95998907   17.67551727   13.99127321    9.58047571   72.16025887\n",
        "   34.21423645  652.91925659   45.39395526]\n",
        "[  5.14778564e+02   4.49003418e+02   2.58098297e+02   2.39999843e+00\n",
        "   2.39994526e+00   2.39991808e+00   9.51237717e+01   7.65685959e+01\n",
        "   4.96108665e+01   3.91984528e+02   1.79132202e+02   3.97777197e+03\n",
        "   2.29259674e+02]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.58428535e+01   4.00174599e+01   4.00003128e+01  -2.39999104e+00\n",
        "  -2.39986372e+00  -2.39996910e+00   2.75036621e+00   2.01213598e+00\n",
        "  -3.81469727e-06   2.00001049e+01   2.00014267e+01   4.17573151e+02\n",
        "   1.54905736e-01]\n",
        "[  99.40098038   68.96914062   45.55354919    0.959759      0.95995784\n",
        "    0.95998907   17.67551727   13.99127321    9.58047571   72.16025887\n",
        "   34.21423645  652.91925659   45.39395526]\n",
        "[  5.86063538e+02   3.55855927e+02   2.65918091e+02   2.39996219e+00\n",
        "   2.39960170e+00   2.39979982e+00   9.38851395e+01   7.12363052e+01\n",
        "   4.79785194e+01   4.29052368e+02   2.08362350e+02   3.93062769e+03\n",
        "   3.20083435e+02]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.77327995e+01   4.00357552e+01   4.00000916e+01  -2.39991784e+00\n",
        "  -2.39999509e+00  -2.39943671e+00   2.91620255e+00   5.22348955e-06\n",
        "   1.65181234e-06   2.00071945e+01   2.00007973e+01   4.46138184e+02\n",
        "   7.81548545e-02]\n",
        "[  99.40098038   68.96914062   45.55354919    0.959759      0.95995784\n",
        "    0.95998907   17.67551727   13.99127321    9.58047571   72.16025887\n",
        "   34.21423645  652.91925659   45.39395526]\n",
        "QCD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../Data/QCD_nm.hdf5\n",
        "[u'test', u'train', u'validation']\n",
        "train exists\n",
        "TTJets_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.hdf5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(200000, 13)\n",
        "[  1.54023181e+03   1.22483472e+03   4.82061493e+02   2.39897490e+00\n",
        "   2.39927101e+00   2.39998937e+00   1.72343338e+02   2.28914505e+02\n",
        "   1.08321480e+02   7.26876099e+02   2.65832977e+02   4.43856348e+03\n",
        "   6.58752991e+02]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.32168388e+01   4.00576324e+01   4.00000648e+01  -2.39894176e+00\n",
        "  -2.39939594e+00  -2.39942789e+00  -4.71004955e-02  -6.50130287e-02\n",
        "  -5.32724969e-02   2.00015125e+01   2.00009251e+01   4.09587067e+02\n",
        "   1.63959324e-01]\n",
        "[ 299.40299454  236.95541687   88.41228561    0.95958333    0.95973339\n",
        "    0.95988345   34.4780877    45.79590361   21.67495046  141.37491722\n",
        "   49.16641045  805.79528198  131.71780628]\n",
        "[  1.76454138e+03   1.38695557e+03   7.01660706e+02   2.39995193e+00\n",
        "   2.39981866e+00   2.39989185e+00   1.82749649e+02   1.75979630e+02\n",
        "   9.32550278e+01   8.26959656e+02   2.88550110e+02   5.38849756e+03\n",
        "   6.92465698e+02]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.03417168e+01   4.00244446e+01   4.00003853e+01  -2.39941263e+00\n",
        "  -2.39987230e+00  -2.39977717e+00  -1.44497424e-01  -6.98273182e-02\n",
        "  -5.04242443e-02   2.00021477e+01   2.00028114e+01   3.52309906e+02\n",
        "   1.68671474e-01]\n",
        "[ 299.40299454  236.95541687   88.41228561    0.95958333    0.95973339\n",
        "    0.95988345   34.4780877    45.79590361   21.67495046  141.37491722\n",
        "   49.16641045  805.79528198  131.71780628]\n",
        "[  1.48361145e+03   1.37153284e+03   4.79813721e+02   2.39988637e+00\n",
        "   2.39973903e+00   2.39934278e+00   1.83169357e+02   2.34606842e+02\n",
        "   8.27312088e+01   7.55546387e+02   2.30830002e+02   4.56846338e+03\n",
        "   1.27773706e+03]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.07358093e+01   4.00199165e+01   4.00010414e+01  -2.39998841e+00\n",
        "  -2.39988327e+00  -2.39999700e+00  -1.95750579e-01  -7.72859007e-02\n",
        "  -6.00571074e-02   2.00015736e+01   2.00002804e+01   3.44542816e+02\n",
        "   1.37201935e-01]\n",
        "[ 299.40299454  236.95541687   88.41228561    0.95958333    0.95973339\n",
        "    0.95988345   34.4780877    45.79590361   21.67495046  141.37491722\n",
        "   49.16641045  805.79528198  131.71780628]\n",
        "TTJets"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../Data/TTJets_nm.hdf5\n",
        "[u'test', u'train', u'validation']\n",
        "train exists\n",
        "WJetsToLNu_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.hdf5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(200000, 13)\n",
        "[  1.04891699e+03   9.72027649e+02   6.00982117e+02   2.39949489e+00\n",
        "   2.39985847e+00   2.39885235e+00   1.12557823e+02   1.17037239e+02\n",
        "   5.38112831e+01   6.94269775e+02   2.91101257e+02   3.80865015e+03\n",
        "   6.79464905e+02]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.00387726e+01   4.00000572e+01   4.00002747e+01  -2.39987516e+00\n",
        "  -2.39975262e+00  -2.39996195e+00  -7.62143955e-02  -1.40950531e-01\n",
        "  -5.13005555e-02   2.00016193e+01   2.00059986e+01   1.79637985e+02\n",
        "   3.21254492e-01]\n",
        "[ 201.77564392  186.40551834  112.19636841    0.95987401    0.95992222\n",
        "    0.95976286   22.52680752   23.43563792   10.77251673  134.85363121\n",
        "   54.21905174  725.80243225  135.82873006]\n",
        "[  1.60589661e+03   1.37365588e+03   5.86735657e+02   2.39993763e+00\n",
        "   2.39988470e+00   2.39999890e+00   1.59846741e+02   1.33395035e+02\n",
        "   5.49675407e+01   6.21228943e+02   2.77253906e+02   4.22343750e+03\n",
        "   6.66478210e+02]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.00017776e+01   4.00002975e+01   4.00002861e+01  -2.39999795e+00\n",
        "  -2.39988542e+00  -2.39984226e+00  -1.48812190e-01  -1.43654123e-01\n",
        "  -1.15605935e-01   2.00052280e+01   2.00021038e+01   2.04299225e+02\n",
        "   1.04868472e-01]\n",
        "[ 201.77564392  186.40551834  112.19636841    0.95987401    0.95992222\n",
        "    0.95976286   22.52680752   23.43563792   10.77251673  134.85363121\n",
        "   54.21905174  725.80243225  135.82873006]\n",
        "[  1.93718811e+03   1.85799463e+03   5.20676697e+02   2.39999986e+00\n",
        "   2.39995599e+00   2.39990926e+00   1.74139313e+02   1.67405472e+02\n",
        "   4.76897240e+01   7.39481262e+02   3.06199341e+02   4.84626123e+03\n",
        "   7.34140381e+02]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  4.00140533e+01   4.00002632e+01   4.00002823e+01  -2.39992309e+00\n",
        "  -2.39997339e+00  -2.39998579e+00  -1.28738850e-01  -1.28460586e-01\n",
        "  -1.19817778e-01   2.00005856e+01   2.00007935e+01   1.93137344e+02\n",
        "   2.15970054e-01]\n",
        "[ 201.77564392  186.40551834  112.19636841    0.95987401    0.95992222\n",
        "    0.95976286   22.52680752   23.43563792   10.77251673  134.85363121\n",
        "   54.21905174  725.80243225  135.82873006]\n",
        "WJetsToLNu"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "../Data/WJetsToLNu_nm.hdf5\n",
        "[u'test', u'train', u'validation']\n",
        "train exists\n",
        "['jetPt:0' 'jetPt:1' 'jetPt:2' 'jetEta:0' 'jetEta:1' 'jetEta:2' 'jetMass:0'\n",
        " 'jetMass:1' 'jetMass:2' 'elePt:0' 'elePt:1' 'metPt' 'sumMET']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train a NADE on the datasets \n",
      "# nades = {} \n",
      "lr = 0.05\n",
      "hl = 2\n",
      "epochs = 15\n",
      "pe = 2\n",
      "\n",
      "'''\n",
      "Each epoch takes ~250s \n",
      "1 QCD: Successful, loglikelihood \\approx -13\n",
      "2 TTJets: Successful, loglikehood \\approx -11\n",
      "3 WJets: \n",
      "'''\n",
      "\n",
      "io_training = {} \n",
      "for (i, label) in enumerate(labels):\n",
      "    io_training[i] = '../Data/%s_nm.hdf5'%label \n",
      "    \n",
      "for i in [2]:\n",
      "    print 'creating NADE...'\n",
      "    print 'training data:', io_training[i]\n",
      "    nades[i] = nade(label = labels[i], resultspath = '../Data/NADE/New_nm/', dataset = io_training[i], hlayers = hl, lr = lr, epochs = epochs, pretraining_epochs = pe)\n",
      "    print 'training starts...'\n",
      "    nades[i].run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating NADE...\n",
        "training data: ../Data/WJetsToLNu_nm.hdf5\n",
        "training starts...\n",
        "['pretraining_1', 1]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 20.5817795709\n",
        "\tconfiguration : {'learning_rate': array(0.05), 'updates_per_epoch': 100, 'momentum': array(0.0), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438690996.22896, 8.9113130569458]\n",
        "['pretraining_1', 2]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 13.5795459377\n",
        "\tconfiguration : {'learning_rate': array(0.03333333333333334), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438690997.050239, 0.8212790489196777]\n",
        "['pretraining_2', 1]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 15.7086714084\n",
        "\tconfiguration : {'learning_rate': array(0.05), 'updates_per_epoch': 100, 'momentum': array(0.0), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691006.713185, 8.951174974441528]\n",
        "['pretraining_2', 2]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 12.0810408146\n",
        "\tconfiguration : {'learning_rate': array(0.03333333333333334), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691007.632241, 0.9190559387207031]\n",
        "['training', 1]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 10.4428578527\n",
        "\tvalidation_loss : {'estimation': 10.023185716529289, 'se': 0.0058115225598529821}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.05), 'updates_per_epoch': 100, 'momentum': array(0.0), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691138.940517, 131.30644488334656]\n",
        "['training', 2]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 11.2960691311\n",
        "\tvalidation_loss : {'estimation': 11.786603915497018, 'se': 0.005582824965433498}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.046875), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691257.509845, 118.56932806968689]\n",
        "['training', 3]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 11.1599904843\n",
        "\tvalidation_loss : {'estimation': 10.856510599371038, 'se': 0.0055968871434630028}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.04375), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691373.180066, 115.67022109031677]\n",
        "['training', 4]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 10.905428176\n",
        "\tvalidation_loss : {'estimation': 10.886468709762999, 'se': 0.0056107090152562773}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.040624999999999994), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691491.620046, 118.43997979164124]\n",
        "['training', 5]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 10.6824273184\n",
        "\tvalidation_loss : {'estimation': 10.535673375959135, 'se': 0.0060612197285189445}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.03749999999999999), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691614.430543, 122.81049704551697]\n",
        "['training', 6]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 10.6194817221\n",
        "\tvalidation_loss : {'estimation': 10.335667871378158, 'se': 0.0059364799980782404}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.03437499999999999), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691736.267088, 121.83654499053955]\n",
        "['training', 7]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 10.3426282018\n",
        "\tvalidation_loss : {'estimation': 10.813728001350849, 'se': 0.0067495013526540117}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.03124999999999999), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691854.339739, 118.07265114784241]\n",
        "['training', 8]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 10.198029383\n",
        "\tvalidation_loss : {'estimation': 10.53115623188182, 'se': 0.0060119476263563168}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.02812499999999999), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438691971.327727, 116.9879879951477]\n",
        "['training', 9]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 10.2305910049\n",
        "\tvalidation_loss : {'estimation': 10.009478894962049, 'se': 0.0056206088363134144}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.02499999999999999), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438692095.454325, 124.12659788131714]\n",
        "['training', 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 10.0431218494\n",
        "\tvalidation_loss : {'estimation': 9.9873863899310873, 'se': 0.0058537323479937011}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.02187499999999999), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438692212.865091, 117.41076612472534]\n",
        "['training', 11]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 9.8472318178\n",
        "\tvalidation_loss : {'estimation': 9.7634233480083701, 'se': 0.0057449769710953965}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.018749999999999992), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438692327.450779, 114.58568787574768]\n",
        "['training', 12]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 9.61272186733\n",
        "\tvalidation_loss : {'estimation': 9.7169590334245335, 'se': 0.0058540460977572839}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.015624999999999993), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438692446.590957, 119.14017796516418]\n",
        "['training', 13]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 9.51382367102\n",
        "\tvalidation_loss : {'estimation': 9.5837835647497123, 'se': 0.0059541057205619724}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.012499999999999994), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438692565.517187, 118.92623019218445]\n",
        "['training', 14]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 9.39781782881\n",
        "\tvalidation_loss : {'estimation': 9.6096599440097794, 'se': 0.0061260380180478812}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.009374999999999994), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438692684.967603, 119.45041584968567]\n",
        "['training', 15]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\ttraining_loss : 9.18960555352\n",
        "\tvalidation_loss : {'estimation': 9.1762902236689179, 'se': 0.006038283552555577}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tconfiguration : {'learning_rate': array(0.006249999999999994), 'updates_per_epoch': 100, 'momentum': array(0.9), 'minibatch_size': 100}\n",
        "\ttimestamp : [1438692806.75176, 121.78415703773499]\n",
        "[]\n",
        "\t : Config {'q': 20, 'h': 100, 'wd': 0.02, 'lr': 0.05}\n",
        "\t : Training average loss\t-9.353622"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t : *Validation mean\t-9.225642 \t(se: 0.037595)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t : Validation detail #1 mean\t-9.280920 \t(se: 0.015632)\n",
        "\t : Validation detail #2 mean\t-9.088377 \t(se: 0.015193)\n",
        "\t : Validation detail #3 mean\t-9.000723 \t(se: 0.015634)\n",
        "\t : Validation detail #4 mean\t-9.214451 \t(se: 0.015362)\n",
        "\t : Validation detail #5 mean\t-9.139507 \t(se: 0.015515)\n",
        "\t : Validation detail #6 mean\t-9.312159 \t(se: 0.015332)\n",
        "\t : Validation detail #7 mean\t-9.360642 \t(se: 0.015955)\n",
        "\t : Validation detail #8 mean\t-9.206814 \t(se: 0.015324)\n",
        "\t : Validation detail #9 mean\t-9.346392 \t(se: 0.015487)\n",
        "\t : Validation detail #10 mean\t-9.306430 \t(se: 0.015644)\n",
        "\t : *Test mean\t-9.212676 \t(se: 0.037958)\n",
        "\t : Test detail #1 mean\t-9.264322 \t(se: 0.015650)\n",
        "\t : Test detail #2 mean\t-9.074545 \t(se: 0.015200)\n",
        "\t : Test detail #3 mean\t-8.984349 \t(se: 0.015667)\n",
        "\t : Test detail #4 mean\t-9.203452 \t(se: 0.015446)\n",
        "\t : Test detail #5 mean\t-9.122587 \t(se: 0.015531)\n",
        "\t : Test detail #6 mean\t-9.298351 \t(se: 0.015397)\n",
        "\t : Test detail #7 mean\t-9.348786 \t(se: 0.015995)\n",
        "\t : Test detail #8 mean\t-9.202990 \t(se: 0.015401)\n",
        "\t : Test detail #9 mean\t-9.338445 \t(se: 0.015568)\n",
        "\t : Test detail #10 mean\t-9.288930 \t(se: 0.015651)\n"
       ]
      }
     ],
     "prompt_number": 46
    }
   ],
   "metadata": {}
  }
 ]
}